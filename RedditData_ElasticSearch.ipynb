{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Sample Data to ElasticSearch indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> \"Author\" : \"Syed Owais Chishti\"\n",
    "\n",
    ">\"Task\" : \"Indexing Reddit Data with Elastic Search in Python.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "els = Elasticsearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "timeframe = 'Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Schema for Index.\n",
    "\n",
    "Index Name : redditData,\n",
    "\n",
    "type : dbalter,\n",
    "\n",
    "fields : [\n",
    "parent_id : TEXT,\n",
    "comment_id : TEXT,\n",
    "parent : TEXT,\n",
    "comment : TEXT,\n",
    "subreddit : TEXT,\n",
    "unix : INT,\n",
    "score : INT\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'redditdata'}\n"
     ]
    }
   ],
   "source": [
    "def create_table():    \n",
    "    m = {\n",
    "        \"mappings\": {\n",
    "            \"dbalter\": {\n",
    "                \"properties\": {\n",
    "                    \"parent_id\": {\n",
    "                        \"type\": \"text\"\n",
    "                    },\n",
    "                    \"comment_id\":{\n",
    "                        \"type\": \"text\"\n",
    "                    },\n",
    "                    \"parent\":{\n",
    "                        \"type\": \"text\",\n",
    "                        \"analyzer\": \"standard\"\n",
    "                    },\n",
    "                    \"comment\": {\n",
    "                        \"type\": \"text\",\n",
    "                        \"analyzer\": \"standard\"\n",
    "                    },\n",
    "                    \"subreddit\": {\n",
    "                        \"type\": \"text\"\n",
    "                    },\n",
    "                    \"unix\": {\n",
    "                        \"type\": \"integer\"\n",
    "                    },\n",
    "                    \"score\": {\n",
    "                        \"type\": \"integer\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    Q1 = els.indices.create(index='redditdata', body=m)\n",
    "    return Q1\n",
    "print(create_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(data):\n",
    "    data = data.replace('\\n',' newlinechar ').replace('\\r',' newlinechar ').replace('\"',\"'\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_parent(pid):\n",
    "    try:\n",
    "        #sql = \"SELECT comment FROM parent_reply WHERE comment_id = '{}' LIMIT 1\".format(pid)\n",
    "        result = els.search(index='redditdata', body={\"query\":{\"match\":{\"comment_id\":\"{}\".format(pid)}}})\n",
    "        if result['hits']['hits'] != []:\n",
    "            result = result['hits']['hits'][0]['_source']['comment']\n",
    "            #print(\"find_parent Function: \", result)\n",
    "            return result\n",
    "        else: return False\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_existing_score(pid):\n",
    "    try:\n",
    "        #sql = \"SELECT score FROM parent_reply WHERE parent_id = '{}' LIMIT 1\".format(pid)\n",
    "        result = els.search(index='redditdata',body={\"query\":{\"match\":{\"parent_id\":\"{}\".format(pid)}}})\n",
    "        if result ['hits']['hits'] != []:\n",
    "            result = result['hits']['hits'][0]['_source']['score']\n",
    "            result = int(result)\n",
    "            #print(\"find_existing_score Function: \", result)\n",
    "            return result\n",
    "        else: return False\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acceptable(data):\n",
    "    if len(data.split(' ')) > 50 or len(data) < 1:\n",
    "        return False\n",
    "    elif len(data) > 1000:\n",
    "        return False\n",
    "    elif data == '[deleted]':\n",
    "        return False\n",
    "    elif data == '[removed]':\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_insert_replace_comment(commentid,parentid,parent,comment,subreddit,time,score):\n",
    "    try:\n",
    "        #sql = \"\"\"UPDATE parent_reply SET parent_id = ?, comment_id = ?, parent = ?, comment = ?, \\\n",
    "        #subreddit = ?, unix = ?, score = ? WHERE parent_id =?;\"\"\".format(parentid, commentid, \n",
    "        #parent, comment, subreddit, int(time), score, parentid)\n",
    "        pids = []\n",
    "        m1 = {\n",
    "            \"query\":{\n",
    "                \"match\" : {\"parent_id\": '{}'.format(parentid)}\n",
    "            }\n",
    "        }\n",
    "        R1 = els.search(index='redditdata', body=m1)\n",
    "        if R1['hits']['hits'] != []:\n",
    "            pids.append(R1['hits']['hits'][0]['_id'])\n",
    "        else:\n",
    "            print(\"Error retreiving ids.\", R1)\n",
    "        \n",
    "        m2 = {\n",
    "            \"doc\" : {\"parent_id\": '{0}'.format(parentid), \"comment_id\": '{}'.format(commentid),\n",
    "                    \"parent\": '{}'.format(parent), \"comment\": '{}'.format(comment),\n",
    "                    \"subreddit\": '{}'.format(subreddit), \"unix\": int(time), \n",
    "                    \"score\": score}\n",
    "        }\n",
    "        for eachID in pids:\n",
    "            try:\n",
    "                els.update(index='redditdata', doc_type='dbalter',id='{}'.format(eachID), body=m2)\n",
    "            except Exception as e:\n",
    "                print(\"Error updating data.\", e)\n",
    "    except Exception as e:\n",
    "        print('sql_insert_replace_comment Function',str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_insert_has_parent(commentid,parentid,parent,comment,subreddit,time,score,givenID):\n",
    "    try:\n",
    "        #sql = \"\"\"INSERT INTO parent_reply (parent_id, comment_id, parent, comment, subreddit, unix, score) \n",
    "        #VALUES (\"{}\",\"{}\",\"{}\",\"{}\",\"{}\",{},{});\"\"\".format(parentid, commentid, parent, comment, subreddit, int(time), score)\n",
    "        m = {\n",
    "            \"parent_id\": '{}'.format(parentid),\n",
    "            \"comment_id\": '{}'.format(commentid),\n",
    "            \"parent\": '{}'.format(parent),\n",
    "            \"comment\": '{}'.format(comment),\n",
    "            \"subreddit\": '{}'.format(subreddit),\n",
    "            \"unix\": int(time),\n",
    "            \"score\": score\n",
    "        }\n",
    "        R1 = els.index(index='redditdata', doc_type='dbalter', id='{}'.format(givenID), body=m)\n",
    "    except Exception as e:\n",
    "        print('sql_insert_has_parent',str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_insert_no_parent(commentid,parentid,comment,subreddit,time,score,givenID):\n",
    "    try:\n",
    "        #sql = \"\"\"INSERT INTO parent_reply (parent_id, comment_id, comment, subreddit, unix, score) \n",
    "        #VALUES (\"{}\",\"{}\",\"{}\",\"{}\",{},{});\"\"\".format(parentid, commentid, comment, subreddit, int(time), score)\n",
    "        m = {\n",
    "            \"parent_id\": '{}'.format(parentid),\n",
    "            \"comment_id\": '{}'.format(commentid),\n",
    "            \"parent\" : '{}'.format('NULL'),\n",
    "            \"comment\": '{}'.format(comment),\n",
    "            \"subreddit\": '{}'.format(subreddit),\n",
    "            \"unix\": int(time),\n",
    "            \"score\": score\n",
    "        }\n",
    "        R1 = els.index(index='redditdata', doc_type='dbalter', id='{}'.format(givenID), body=m)\n",
    "    except Exception as e:\n",
    "        print('sql_insert_no_parent',str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import linecache\n",
    "import sys\n",
    "\n",
    "def PrintException():\n",
    "    exc_type, exc_obj, tb = sys.exc_info()\n",
    "    f = tb.tb_frame\n",
    "    lineno = tb.tb_lineno\n",
    "    filename = f.f_code.co_filename\n",
    "    linecache.checkcache(filename)\n",
    "    line = linecache.getline(filename, lineno, f.f_globals)\n",
    "    print ('EXCEPTION IN ({}, LINE {} \"{}\"): {}'.format(filename, lineno, line.strip(), exc_obj))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_counter = 0\n",
    "paired_rows = 0\n",
    "givenID = 1\n",
    "with open('Data',encoding='utf8', errors='ignore')as f:\n",
    "    try:\n",
    "        for row in f:\n",
    "            row_counter += 1\n",
    "            row = json.loads(row)\n",
    "            parent_id = row['parent_id']\n",
    "            body = format_data(row['body'])\n",
    "            created_utc = row['created_utc']\n",
    "            score = row['score']\n",
    "            comment_id = row['name']\n",
    "            subreddit = row['subreddit']\n",
    "            parent_data = find_parent(parent_id)\n",
    "            if score >= 2:\n",
    "                existing_comment_score = find_existing_score(parent_id)\n",
    "                if existing_comment_score:\n",
    "                    if score > existing_comment_score:\n",
    "                        if acceptable(body):\n",
    "                            sql_insert_replace_comment(comment_id,parent_id,parent_data,body,subreddit,created_utc,score)\n",
    "                else:\n",
    "                    if acceptable(body):\n",
    "                        if parent_data:\n",
    "                            sql_insert_has_parent(comment_id,parent_id,parent_data,body,subreddit,created_utc,score, givenID)\n",
    "                            paired_rows += 1\n",
    "                            givenID += 1\n",
    "                        else:\n",
    "                            sql_insert_no_parent(comment_id,parent_id,body,subreddit,created_utc,score, givenID)\n",
    "                            givenID += 1\n",
    "\n",
    "            if row_counter % 100000 == 0:\n",
    "                    print('Total Rows Read: {}, Paired Rows: {}, Time: {}'.format(row_counter, paired_rows, str(datetime.now())))\n",
    "    except Exception as e:\n",
    "        print(\"main\", e)\n",
    "        PrintException()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Index to Files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>parent</th>\n",
       "      <th>comment</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>unix</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>erfge</td>\n",
       "      <td>bebae</td>\n",
       "      <td>rgjuj</td>\n",
       "      <td>etb</td>\n",
       "      <td>ghr</td>\n",
       "      <td>244</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rgjuj</td>\n",
       "      <td>wref</td>\n",
       "      <td>adfa</td>\n",
       "      <td>ghr</td>\n",
       "      <td>rgjuj</td>\n",
       "      <td>361</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ghr</td>\n",
       "      <td>adfa</td>\n",
       "      <td>ghr</td>\n",
       "      <td>bebae</td>\n",
       "      <td>rgjuj</td>\n",
       "      <td>366</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wref</td>\n",
       "      <td>ghr</td>\n",
       "      <td>etb</td>\n",
       "      <td>ghr</td>\n",
       "      <td>rgjuj</td>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>erfge</td>\n",
       "      <td>adfa</td>\n",
       "      <td>beb</td>\n",
       "      <td>beb</td>\n",
       "      <td>wref</td>\n",
       "      <td>478</td>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>etb</td>\n",
       "      <td>erfge</td>\n",
       "      <td>beb</td>\n",
       "      <td>bsdthrt</td>\n",
       "      <td>erfge</td>\n",
       "      <td>505</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bsdthrt</td>\n",
       "      <td>erfge</td>\n",
       "      <td>adfa</td>\n",
       "      <td>wref</td>\n",
       "      <td>beb</td>\n",
       "      <td>508</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>beb</td>\n",
       "      <td>erfge</td>\n",
       "      <td>bsdthrt</td>\n",
       "      <td>ghr</td>\n",
       "      <td>adfa</td>\n",
       "      <td>510</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bebae</td>\n",
       "      <td>bebae</td>\n",
       "      <td>adfa</td>\n",
       "      <td>ghr</td>\n",
       "      <td>beb</td>\n",
       "      <td>627</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ghr</td>\n",
       "      <td>etb</td>\n",
       "      <td>ghr</td>\n",
       "      <td>adfa</td>\n",
       "      <td>wref</td>\n",
       "      <td>638</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parent_id comment_id   parent  comment subreddit unix score\n",
       "0     erfge      bebae    rgjuj      etb       ghr  244   244\n",
       "1     rgjuj       wref     adfa      ghr     rgjuj  361   361\n",
       "2       ghr       adfa      ghr    bebae     rgjuj  366   366\n",
       "3      wref        ghr      etb      ghr     rgjuj  370   370\n",
       "4     erfge       adfa      beb      beb      wref  478   478\n",
       "5       etb      erfge      beb  bsdthrt     erfge  505   505\n",
       "6   bsdthrt      erfge     adfa     wref       beb  508   508\n",
       "7       beb      erfge  bsdthrt      ghr      adfa  510   510\n",
       "8     bebae      bebae     adfa      ghr       beb  627   627\n",
       "9       ghr        etb      ghr     adfa      wref  638   638"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.concat([pd.Series(d) for d in dicts], axis=1).fillna(0).T\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "els = Elasticsearch()\n",
    "import pandas as pd\n",
    "import linecache\n",
    "import sys\n",
    "\n",
    "def PrintException():\n",
    "    exc_type, exc_obj, tb = sys.exc_info()\n",
    "    f = tb.tb_frame\n",
    "    lineno = tb.tb_lineno\n",
    "    filename = f.f_code.co_filename\n",
    "    linecache.checkcache(filename)\n",
    "    line = linecache.getline(filename, lineno, f.f_globals)\n",
    "    print ('EXCEPTION IN ({}, LINE {} \"{}\"): {}'.format(filename, lineno, line.strip(), exc_obj))\n",
    "\n",
    "\n",
    "\n",
    "limit = 5000\n",
    "last_unix = 0\n",
    "cur_length = limit\n",
    "counter = 0\n",
    "test_done = False\n",
    "try:\n",
    "    while cur_length == limit:\n",
    "        m = {\n",
    "       \"query\": {\n",
    "         \"bool\": {\n",
    "           \"must_not\": [\n",
    "             {\n",
    "               \"match\": {\n",
    "               \"score\": 0\n",
    "             }\n",
    "             },\n",
    "             {\n",
    "               \"match\": {\n",
    "                 \"parent\": \"NULL\"\n",
    "               }\n",
    "             }\n",
    "           ],\n",
    "           \"filter\": {\n",
    "             \"range\": {\n",
    "               \"unix\": {\n",
    "                 \"gt\": last_unix\n",
    "               }\n",
    "             }\n",
    "           }\n",
    "         }\n",
    "       }, \n",
    "        \"sort\": [\n",
    "            {\n",
    "                \"unix\": {\n",
    "                    \"order\" : \"asc\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        }\n",
    "        Res = els.search(index='redditdata', body=m)\n",
    "        dfdicts = []\n",
    "        for i in range(len(Res['hits']['hits'])):\n",
    "            dfdicts.append(Res['hits']['hits'][i]['_source'])\n",
    "        df = pd.concat([pd.Series(d) for d in dfdicts], axis=1).fillna(0).T\n",
    "        last_unix = df.tail(1)['unix'].values[0]\n",
    "        cur_length = len(df)\n",
    "\n",
    "        if not test_done:\n",
    "            with open('test.from','a', encoding='utf8') as f:\n",
    "                for content in df['parent'].values:\n",
    "                    f.write(content+'\\n')\n",
    "\n",
    "            with open('test.to','a', encoding='utf8') as f:\n",
    "                for content in df['comment'].values:\n",
    "                    f.write(str(content)+'\\n')\n",
    "\n",
    "            test_done = True\n",
    "\n",
    "        else:\n",
    "            with open('train.from','a', encoding='utf8') as f:\n",
    "                for content in df['parent'].values:\n",
    "                    f.write(content+'\\n')\n",
    "\n",
    "            with open('train.to','a', encoding='utf8') as f:\n",
    "                for content in df['comment'].values:\n",
    "                    f.write(str(content)+'\\n')\n",
    "\n",
    "        counter += 1\n",
    "        if counter % 20 == 0:\n",
    "            print(counter*limit,'rows completed so far')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    PrintException()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
